{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3f3bf4a",
   "metadata": {},
   "source": [
    "# Aerospace Component Failure Prediction Model - Practical Application Example\n",
    "\n",
    "This notebook demonstrates the practical application of the trained LSTM model for aerospace component maintenance forecasting. It showcases real-world business value through inventory optimization, cost reduction analysis, and supply chain improvements.\n",
    "\n",
    "## Key Business Applications:\n",
    "- Component demand forecasting and inventory optimization\n",
    "- Risk assessment and mitigation strategies\n",
    "- Cost-benefit analysis for predictive maintenance\n",
    "- Supply chain efficiency improvements\n",
    "- Service level enhancement metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8431a258",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "from keras.models import load_model\n",
    "from keras.losses import mean_squared_error\n",
    "from keras.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "tf.keras.metrics.mse = mse\n",
    "\n",
    "# Load saved model\n",
    "input_path = os.path.join('private', 'data', 'training_data')\n",
    "model_path = os.path.join(input_path, 'time_based_maintenance_model.h5')\n",
    "\n",
    "# Custom objects dictionary \n",
    "custom_objects = {\n",
    "    'mse': mse,\n",
    "    'mean_squared_error': mean_squared_error\n",
    "}\n",
    "\n",
    "# Load the model\n",
    "model = load_model(model_path, custom_objects=custom_objects)\n",
    "\n",
    "# Print model summary\n",
    "model.summary()\n",
    "\n",
    "# Load test data\n",
    "# test_data_path = os.path.join(input_path, 'test_data')\n",
    "test_data_path = os.path.join(input_path, 'test_data.npz')\n",
    "test_data = np.load(test_data_path)\n",
    "\n",
    "# Test data content\n",
    "print(\"Arrays in the test data file:\", test_data.files)\n",
    "X_test = test_data['X_test']\n",
    "y_test = test_data['y_test'] \n",
    "y_test_original = test_data['y_test_original'] \n",
    "part_ids = test_data['part_ids']\n",
    "time_periods = test_data['time_periods']\n",
    "\n",
    "print(f\"Part IDs shape: {part_ids.shape}\")\n",
    "print(f\"Time periods shape: {time_periods.shape}\")\n",
    "\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")\n",
    "print(f\"y_test_original shape: {y_test_original.shape}\")\n",
    "\n",
    "print(\"\\nSample target values:\")\n",
    "print(f\"First 5 y_test values (log scale): {y_test[:5]}\")\n",
    "print(f\"First 5 y_test_original values (original scale): {y_test_original[:5]}\")\n",
    "print(f\"First 5 part_ids: {part_ids[:5]}\")\n",
    "print(f\"First 5 time_periods: {time_periods[:5]}\")\n",
    "\n",
    "print(\"\\nMaking predictions on test data...\")\n",
    "predictions = model.predict(X_test, batch_size=32, verbose=1)\n",
    "predictions_original = np.expm1(predictions)  # Inverse of log1p transform\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    'part_id': part_ids,\n",
    "    'time_period': time_periods,\n",
    "    'actual_demand': y_test_original,\n",
    "    'predicted_demand': predictions_original.flatten()\n",
    "})\n",
    "\n",
    "# Random parts costs - using anonymized cost ranges for demonstration\n",
    "random.seed(42)  # For reproducibility\n",
    "part_costs = {}\n",
    "\n",
    "unique_part_ids = np.unique(part_ids)\n",
    "for part_id in unique_part_ids:\n",
    "    cost = random.uniform(50, 2500)  # Anonymized cost range\n",
    "    part_costs[part_id] = round(cost, 2)\n",
    "print(\"Sample anonymized part costs:\")\n",
    "for part_id in unique_part_ids[:5]:\n",
    "    print(f\"Part {part_id}: ${part_costs[part_id]}\")\n",
    "\n",
    "\n",
    "\n",
    "# Parts needed by week\n",
    "results_df['date'] = pd.to_datetime(results_df['time_period'].astype(str), format='%Y%m')\n",
    "results_df['week'] = results_df['date'] + pd.to_timedelta([random.randint(1, 28) for _ in range(len(results_df))], unit='D')\n",
    "results_df['week'] = results_df['week'].dt.isocalendar().week\n",
    "\n",
    "sample_parts = random.sample(list(unique_part_ids), 5)\n",
    "\n",
    "weekly_forecast = pd.pivot_table(\n",
    "    results_df[results_df['part_id'].isin(sample_parts)],\n",
    "    values='predicted_demand',\n",
    "    index='week',\n",
    "    columns='part_id',\n",
    "    aggfunc='sum'\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "weekly_forecast.plot(kind='bar', stacked=False)\n",
    "plt.title('Weekly Component Demand Forecast')\n",
    "plt.xlabel('Week Number')\n",
    "plt.ylabel('Predicted Component Demand')\n",
    "plt.legend(title='Part ID')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.savefig('weekly_component_forecast.png')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Calculate potential shortage risk reduction\n",
    "results_df['traditional_shortage_risk'] = 0.15  # Assume 15% shortage risk with traditional method\n",
    "results_df['model_shortage_risk'] = 0.05  # Assume 5% with model-based approach\n",
    "\n",
    "# Calculate cost of shortages (lost revenue, emergency shipping, etc.)\n",
    "avg_shortage_cost = 1500  # Average cost per shortage event\n",
    "results_df['shortage_cost_savings'] = (results_df['traditional_shortage_risk'] - \n",
    "                                      results_df['model_shortage_risk']) * avg_shortage_cost\n",
    "\n",
    "print(f\"\\nTotal annual shortage cost savings: ${results_df['shortage_cost_savings'].sum():.2f}\")\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "risk_comparison = pd.DataFrame({\n",
    "    'Traditional Method': [0.15],\n",
    "    'Model-Based Approach': [0.05]\n",
    "})\n",
    "\n",
    "risk_bar_plot = plt.subplot(121)\n",
    "risk_comparison.plot(kind='bar', ax=risk_bar_plot, color=['#ff9999', '#66b3ff'])\n",
    "risk_bar_plot.set_title('Component Shortage Risk Comparison')\n",
    "risk_bar_plot.set_xlabel('Inventory Method')\n",
    "risk_bar_plot.set_ylabel('Shortage Risk (%)')\n",
    "risk_bar_plot.set_xticklabels([''])\n",
    "risk_bar_plot.legend()\n",
    "risk_bar_plot.set_ylim(0, 0.20)\n",
    "\n",
    "# Convert to percentage for the y-axis labels\n",
    "risk_bar_plot.yaxis.set_major_formatter(plt.FuncFormatter(lambda y, _: '{:.0%}'.format(y)))\n",
    "for i, v in enumerate(risk_comparison.values[0]):\n",
    "    risk_bar_plot.text(i, v + 0.01, f'{v:.0%}', ha='center')\n",
    "\n",
    "# Add a pie chart showing cost impact\n",
    "savings = results_df['shortage_cost_savings'].sum()\n",
    "total_traditional_cost = len(results_df) * 0.15 * avg_shortage_cost\n",
    "remaining_cost = len(results_df) * 0.05 * avg_shortage_cost\n",
    "\n",
    "cost_pie_chart = plt.subplot(122)\n",
    "cost_pie_chart.pie([savings, remaining_cost], \n",
    "        labels=['Cost Savings', 'Remaining Cost'],\n",
    "        autopct='%1.1f%%',\n",
    "        colors=['#66b3ff', '#ff9999'],\n",
    "        startangle=90)\n",
    "cost_pie_chart.set_title(f'Annual Component Shortage Cost Impact\\nTotal Savings: ${savings:,.2f}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('shortage_risk_reduction.png')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Supply Chain Impact\n",
    "supply_chain_data = []\n",
    "\n",
    "for part_id in list(unique_part_ids):\n",
    "    part_predictions = results_df[results_df['part_id'] == part_id]\n",
    "    \n",
    "    # Traditional inventory approach (fixed safety stock)\n",
    "    traditional_safety_stock = 20  # Fixed buffer\n",
    "    traditional_total_inventory = part_predictions['predicted_demand'].sum() + traditional_safety_stock * len(part_predictions)\n",
    "    traditional_inventory_cost = traditional_total_inventory * part_costs[part_id]\n",
    "    \n",
    "    # Model-based approach (dynamic safety stock)\n",
    "    model_variability = part_predictions['predicted_demand'].std()\n",
    "    model_safety_stock = max(5, min(15, int(model_variability)))  # Dynamic buffer based on variability\n",
    "    model_total_inventory = part_predictions['predicted_demand'].sum() + model_safety_stock * len(part_predictions)\n",
    "    model_inventory_cost = model_total_inventory * part_costs[part_id]\n",
    "    \n",
    "    # Calculate metrics\n",
    "    inventory_reduction = traditional_total_inventory - model_total_inventory\n",
    "    cost_savings = traditional_inventory_cost - model_inventory_cost\n",
    "    service_level_improvement = min(15, max(5, random.randint(5, 15)))  # Simulated improvement (%)\n",
    "    \n",
    "    supply_chain_data.append({\n",
    "        'part_id': part_id,\n",
    "        'traditional_inventory': traditional_total_inventory,\n",
    "        'model_inventory': model_total_inventory,\n",
    "        'inventory_reduction': inventory_reduction,\n",
    "        'inventory_reduction_pct': (inventory_reduction / traditional_total_inventory) * 100,\n",
    "        'cost_savings': cost_savings,\n",
    "        'service_level_improvement': service_level_improvement\n",
    "    })\n",
    "\n",
    "supply_chain_df = pd.DataFrame(supply_chain_data)\n",
    "\n",
    "print(\"\\nSupply Chain Impact Summary:\")\n",
    "print(f\"Average inventory reduction: {supply_chain_df['inventory_reduction_pct'].mean():.1f}%\")\n",
    "print(f\"Total cost savings: ${supply_chain_df['cost_savings'].sum():.2f}\")\n",
    "print(f\"Average service level improvement: {supply_chain_df['service_level_improvement'].mean():.1f}%\")\n",
    "\n",
    "sorted_supply_chain_df = supply_chain_df.sort_values(by='cost_savings', ascending=False)\n",
    "top_parts = sorted_supply_chain_df.head(5)  # Get top 5 parts for visualizations\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(top_parts['part_id'].astype(str), top_parts['inventory_reduction_pct'])\n",
    "plt.title('Inventory Reduction by Part (%) - Top 5 Parts')\n",
    "plt.xlabel('Part ID')\n",
    "plt.ylabel('Inventory Reduction (%)')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.savefig('inventory_reduction.png')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "width = 0.35\n",
    "x = np.arange(len(top_parts))\n",
    "plt.bar(x - width/2, top_parts['traditional_inventory'], width, label='Traditional Inventory')\n",
    "plt.bar(x + width/2, top_parts['model_inventory'], width, label='Model-Based Inventory')\n",
    "plt.title('Traditional vs. Model-Based Inventory Levels - Top 5 Parts')\n",
    "plt.xlabel('Part ID')\n",
    "plt.ylabel('Inventory Units')\n",
    "plt.xticks(x, top_parts['part_id'].astype(str))\n",
    "plt.legend()\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.savefig('inventory_comparison.png')\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  },
  "title": "Data Extraction Pipeline"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
